---
title: "AUC im Wandel der Zeiten"
output: html_notebook
---

## Einleitung

TBD

## Berechnung des AUC

Es ist interessant, einmal zum Spaß manuell den AUC zu berechnen, was wir im
Folgenden an einem einfachen Beispiel tun.

### Was ist der AUC?

Aber was ist der AUC eigentlich genau? Sie ist die Fläche unter der ROC-Kurve
("ROC" = Receiver-Operator Characteristic). Was ist die ROC-Kurve? Die ROC-Kurve
beschreibt den Zusammenhang zwischen False Positive Rate (FPR) und True Positive
Rate (TRP) einer Verteilungen von eindimensionalen, kontinuierlichen Messwerten
mit einer zusätzlichen beschreibenden binären Eigenschaft. Der AUC ist eine
Zahl, die sich aus der ROC-Kurve ableitet und welche die Trennbarkeit der
binären Eigenschaft angibt.

### ROC und AUC in einem Beispiel

Die abstrakte Definition läßt sich besser anhand eines Beispiels verstehen.

Nehmen wir an, dass Alice und Bob ein Kabel zwischen sich als
Kommunikationskanal verwenden wollen. Sie einigen sich darauf, dass jede Sekunde
ein Bit übertragen werden soll. Wenn Alice eine Eins übertragen möchte, legt sie
eine Spannung von einem Volt für die Dauer der Sekunde an das Kabel an, will sie
sie eine Null übertragen, dann legt sie keine Spannung an. Bob hat an dem
anderen Ende des Kabels ein Voltmeter angebracht und mittelt für den Verlauf der
Sekunde die anliegende Spannung. Zu ihrer beider Überraschung stellt sich im
Test heraus, dass Bob alle möglichen Spannungen mißt und nicht nur schön klar
null und ein Volt. Um die Übertragungsqualität einmal zu testen, überträgt Alice
daher eine Botschaft und schreibt sich genau auf, in welcher Sekunde sie welche
Spannung angelegt hat, damit sie beide nachher vergleichen können, welche
Spannung wann wie übertragen wurde. Hier sind die Messwerte von 8
Beispielmessungen:

```{r}
botschaft = c(0, 1, 1, 0, 0, 1, 0, 1)
signal = c(-0.19, 0.22, 0.40, -0.10, 0.43, 0.79, 0.25, 0.52)
```

Naiverweise könnte man annehmen, dass man auf Bobs Seite einfach eine Schwelle
von 0.5 Volt zur Trennung der beiden Bits ansetzt, da der Wert zwischen den
beiden Spannungen liegt. Allerdings können wir nicht sicher sein, dass das
Rauschen in der Leitung für beide Bits gleich breit ist oder den Mittelwert 
ungleich verschiebt. In unserem Signal sehen wir keine Spannung größer als ein
Volt, so dass wir davon ausgehen können, dass der Mittelwert von Bit Eins in
Wirklichkeit kleiner als ein Volt ist. Daher muss die Schwelle empirisch
gewählt werden. Alice und Bob gehen daher alle möglichen Werte durch und
notieren sich jeweils, wieviele Einser-Bits richtig und wieviele Nuller-Bits
fälschlich als Eins erkannt werden. Da sie nur eine begrenzte Zahl an Messungen
haben, müssen sie de facto nur jeweils eine Detektionsschwellen betrachten, die
zwischen jeweils zwei Messwerten nach Sortierung liegt:

```{r}
idcs_sortierung = order(signal)
messtabelle = data.frame(botschaft = botschaft[idcs_sortierung],
												 signal = signal[idcs_sortierung])
messtabelle
```

Die Schwellen legen sie als die Mitte zwischen zwei aufeinanderfolgenden Signal-
Werten fest, plus zwei Werte außerhalb des Bereichs von Signal

```{r}
schwelle = c(min(messtabelle$signal) - 1,
						 messtabelle$signal[-8] + diff(messtabelle$signal)/2,
						 max(messtabelle$signal) + 1)
schwelle
```

Dies sind hypothetische Schwellen. Alle Messspanunngen, die größer sind als die
jeweilige Schwelle, werden als Bit Eins klassifiziert. Das machen Alice und Bob
für jede Schwelle und notieren sich die False Positives und True Positives,
geteilt durch die Anzahl der wahren Negatives und Positives, um die Werte als
Raten zu erhalten:

```{r}
positive_tab = data.frame(schwelle = schwelle,
													tpr = sapply(schwelle, function(x) {
														sum(messtabelle$botschaft[messtabelle$signal > x] == 1)
														 })/sum(messtabelle$botschaft == 1),
													fpr = sapply(schwelle, function(x) {
														sum(messtabelle$botschaft[messtabelle$signal > x] == 0)
													})/sum(messtabelle$botschaft == 0))
positive_tab
```

Mit den Werten können wir die ROC-Kurve zeichnen:

```{r}
plot(positive_tab$fpr, positive_tab$tpr, type = "l")
```

Jetzt können wir die Fläche unter der Kurve, die "Area Under Curve", berechnen:

```{r}
0.5*0.25 + 0.75*0.25 + 1*0.5
```

Aber warum machen wir das ganze jetzt? Wir könnten 




Bevor es losgeht, werden die nötigen Libraries geladen.

```{r}
library(ggplot2)     # Plotten
library(pROC)        # ROC berechnen
library(caret)       # Für XGB Tree
library(data.table)  # Weil data.table geil ist
```








Jetzt werden Testdaten erzeugt. Sie bestehen aus einer metrischen Variablen und
einer zu jeder Messung gehörenden Klasse. Die Klasse trennt die metrische
Variable in zwei Verteilungen auf. Die eine Verteilung ist bimodal, nämlich eine
Summe aus zwei Normalverteilungen. Die andere Verteilung ist nur ein einfacher
Gauss. Die Mittelwerte der beiden Verteilungen sind gleich, d.h. der Peak der
unimodalen Verteilung liegt genau zwischen den beiden Peaks der bimodalen
Verteilung:

```{r}
# Die Gesamtzahl der Punkte ist size*4
size = 10000

tach = data.frame(x = c(rnorm(n = size, mean = 0.5), rnorm(size, 3.5), rnorm(2*size, 2)),
                  y = factor(rep(c("no", "yes"), each = 2*size)))

ggplot(tach, aes(x, fill = y)) + geom_density(bw = 0.05, alpha = 0.5)
```

Was genau ist der AUC? Man fährt mit einer Schwelle von links nach rechts durch
die Daten hindurch. Für jeden Wert der Schwelle notiert man sich die False
Positive Rate und die True Positive Rate. Danach werden die beiden Werte
gegeneinader geplottet. Die AUC ist dann die Fläche unter dieser Kurve.

Bisher haben wir den AUC immer als Maß für die Trennbarkeit der Vorhersagen
eines Modells unter der Bedingung der binären Zielvariablen verwendet. Die obige
Verteilung ist klar trennbar. Aber der AUC ist neutral:

```{r}
roc(tach$y, tach$x, algorithm = 3)
```

Die ROC-Kurve aber nicht!

```{r}
plot(roc(tach$y, tach$x, algorithm = 3))
```

Das zeigt uns, dass der AUC ohne die Kurve nicht unter allen Umständen
verwendbar ist. In unserem Fall müssen wir ein Modell zu Hilfe nehmen, es auf
die Daten trainieren und dann erneut die AUC berechnen. Nehmen wir zuerst ein
ganz einfaches Modell. Die Betrachtung der obigen Kurve legt nahe, dass wir für
die Mitte mit `1 < x < 3` "yes" (1) vorhersagen können und "no" (0) sonst. Wir
bekommen eine nicht-neutrale ROC-Kurve

```{r}
tach$naive_pred = as.numeric(tach$x > 1 & tach$x < 3)

plot(roc(tach$y, tach$naive_pred, algorithm = 3))
```

Und der AUC ist

```{r}
roc(tach$y, tach$naive_pred, algorithm = 3)
```

Gehen wir etwas komplexer vor und nehmen ein XGB-Tree-Modell. Die Hyperparameter
werden nicht weiter optimiert:

```{r}
modell_xgb = train(form = as.formula("y ~ x"), data = tach, method = "xgbTree",
                   tuneGrid = expand.grid(nrounds = 20,
                                          max_depth = 6,
                                          eta = 1,
                                          gamma = 1,
                                          colsample_bytree = 1,
                                          subsample = 1,
                                          min_child_weight = 1),
                   trControl = trainControl(method = "none", classProbs = TRUE),
                   metric = "twoClassSummary")

# Die Predictions als neue Spalte anhängen
tach$xgb_predict = predict(modell_xgb, tach, type = "prob")[, 2]
```

Jetzt können wir die Vorhersagen als neue metrische Variable verwenden und die
Verteilungen unter Aufspaltung nach dem Label plotten:

```{r}
ggplot(tach, aes(xgb_predict, fill = y)) + geom_density(bw = 0.01, alpha = 0.5)
```

Der AUC ist entsprechend besser geworden

```{r}
roc(tach$y, tach$xgb_predict, algorithm = 3)
```

(Warum muss es immer `0.76` sein???)

Dazu noch die ROC-Kurve:

```{r}
plot(roc(tach$y, tach$xgb_predict, algorithm = 3))
```

Man kann die Funktion des Modells folgendermaßen verstehen: Es hat die originale
x-Achse genommen, in Segmente eingeteilt, und dann die Segmente nach der 
"Approvalrate" in dem Segment neu sortiert. Nach dieser Sortierung erst ist der
AUC ein gutes Maß für die Trennbarkeit der Verteilungen.

Das ganze können wir auch manuell machen. Wir teilen die x-Achse in kleine
Quantile ein, damit jedes Segment die gleiche Anzahl Beobachtungen hat. Das
macht das `cut()` in Verbindung mit `quantile`. Dann bekommen die Segmente eine
"yes-rate" ("Approvalrate") zugewiesen, indem die Anzahl der `y` mit Wert "yes"
in dem Segment durch die Größe des Segments geteilt wird, und dann sortieren wir
die Segmente nach ihrer yesrate. Das machen wir mit dem kleinen Trick, dass die
Rate zu einem Faktor geändert wird, wodurch die zugrunde liegenden Levels
sortiert werden, um dann die Levels nach `integer` zu konvertieren. Dadurch
verändert sich die Skala, aber das passiert auch durch die obigen
Modellierungen. Der ROC-Analyse sind die Skala sowie die Abstände zwischen den
Bins herzlich egal, es kommt nur auf die richtige Sortierung an:

```{r}
# Ich liebe data.table!
tachdt = as.data.table(tach)

# Die Anzahl der Segmente, in die wir die x-Achse einteilen
anz_segm = 1000

tachdt$quanti = cut(tach$x, breaks = quantile(tach$x, probs = seq(0, 1, length = anz_segm + 1)),
                    labels = as.character(seq(1, anz_segm, by = 1)), include.lowest = TRUE)

# Danach berechnen wir pro Segment die "yesrate", also die Annahmerate, und
# kleben sie an die ursprüngliche Tabelle ran.
tachdt = merge(tachdt, tachdt[, .(yesrate = mean(ifelse(y == "yes", 1, 0))), quanti],
               by = "quanti", all.x = TRUE, sort = FALSE)

# Wenn man die yesrate auf ganze Zahlen abbildet und die Dichten getrennt nach
# der Zielvariable plottet, kommt was schönes heraus!
ggplot(tachdt, aes(as.integer(as.factor(yesrate)), fill = y)) + geom_density(alpha = 0.5, bw = 0.5)
```

Der AUC ist vergleichbar mit dem des XGBTree-Modells:

```{r}
roc(tachdt$y, tachdt$yesrate)
```

Und damit haben wir es! Die AUC kann nicht für allgemeine Verteilungen verwendet
werden, sondern nur in Spezialfällen. In allen anderen Fällen sollte eine
Sortierung stattfinden, um ein vergleichbares Maß für die Trennbarkeit/
Unterschiedlichkeit von Verteilungen zu erhalten, indem man z.B. ein ML-Modell
auf den Daten fittet.






